{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68b1f654-0e8d-4236-8f14-9d6aabe1f537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Encode File...\n",
      "['321654', '852741', '963852']\n",
      "Encode File Loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "imgBackground = cv2.imread('Resources/background.png')\n",
    "\n",
    "#Import mode images in list\n",
    "\n",
    "folderModePath = 'Resources/modes'\n",
    "modePath= os.listdir(folderModePath)\n",
    "imgModeList=[]\n",
    "for path in modePath:\n",
    "    imgModeList.append(cv2.imread(os.path.join(folderModePath, path)))\n",
    "\n",
    "#print(len(imgModeList))\n",
    "\n",
    "#Load the encoding file\n",
    "print(\"Loading Encode File...\")\n",
    "\n",
    "file = open('EncodeFile.p','rb')\n",
    "encodeListKnownWithIds = pickle.load(file)\n",
    "file.close()\n",
    "encodeListKnow,studentIds = encodeListKnownWithIds\n",
    "print(studentIds)\n",
    "print(\"Encode File Loaded\")\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "\n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    faceCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodeCurFrame = face_recognition.face_encodings(imgS, faceCurFrame)\n",
    "    \n",
    "    imgBackground[162:162+480,55:55+640] = img\n",
    "    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[3]\n",
    "    \n",
    "    # cv2.imshow(\"Webcam\", img)\n",
    "    cv2.imshow(\"Face Attendance\", imgBackground)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Exit loop if 'q' is pressed\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ff4b94a-d76f-4fdb-b921-ba96bcbd37f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Encode File...\n",
      "['321654', '852741', '963852']\n",
      "Encode File Loaded\n",
      "known\n",
      "963852\n",
      "known\n",
      "963852\n",
      "known\n",
      "963852\n",
      "known\n",
      "963852\n",
      "known\n",
      "963852\n",
      "known\n",
      "852741\n",
      "known\n",
      "852741\n",
      "known\n",
      "852741\n",
      "known\n",
      "852741\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "imgBackground = cv2.imread('Resources/background.png')\n",
    "\n",
    "#Import mode images in list\n",
    "\n",
    "folderModePath = 'Resources/modes'\n",
    "modePath= os.listdir(folderModePath)\n",
    "imgModeList=[]\n",
    "for path in modePath:\n",
    "    imgModeList.append(cv2.imread(os.path.join(folderModePath, path)))\n",
    "\n",
    "#print(len(imgModeList))\n",
    "\n",
    "#Load the encoding file\n",
    "print(\"Loading Encode File...\")\n",
    "\n",
    "file = open('EncodeFile.p','rb')\n",
    "encodeListKnownWithIds = pickle.load(file)\n",
    "file.close()\n",
    "encodeListKnown,studentIds = encodeListKnownWithIds\n",
    "print(studentIds)\n",
    "print(\"Encode File Loaded\")\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "\n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    faceCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodeCurFrame = face_recognition.face_encodings(imgS, faceCurFrame)\n",
    "    \n",
    "    imgBackground[162:162+480,55:55+640] = img\n",
    "    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[3]\n",
    "    \n",
    "    for encodeFace,faceLoc in zip(encodeCurFrame, faceCurFrame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown,encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown,encodeFace)\n",
    "        \n",
    "        #print(\"matches\", matches)\n",
    "        #print(\"faceDis\", faceDis)\n",
    "        \n",
    "        matchIndex = np.argmin(faceDis)\n",
    "\n",
    "        if matches[matchIndex]:\n",
    "            #print(\"known\")\n",
    "            #print(studentIds[matchIndex])\n",
    "            \n",
    "    \n",
    "    # cv2.imshow(\"Webcam\", img)\n",
    "    cv2.imshow(\"Face Attendance\", imgBackground)\n",
    "\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):  # Exit loop if 'q' is pressed\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f29e36b-a239-4166-8a0d-9905b07966e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Encode File...\n",
      "['321654', '852741', '963852']\n",
      "Encode File Loaded\n",
      "{'last_attendance_time': '2024-03-25 00:54:34', 'major': 'CSE', 'name': 'Akash S', 'standing': 'G', 'starting_year': 2020, 'total_attendance': 7, 'year': 4}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import cvzone \n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import db\n",
    "from firebase_admin import storage\n",
    "\n",
    "\n",
    "cred = credentials.Certificate(\"serviceAccountKey.json\")\n",
    "firebase_admin.initialize_app(cred,{\n",
    "    'databaseURL':\"https://faceattendancerealtime-a1b14-default-rtdb.firebaseio.com/\",\n",
    "    'storageBucket':\"faceattendancerealtime-a1b14.appspot.com\"\n",
    "})\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "imgBackground = cv2.imread('Resources/background.png')\n",
    "\n",
    "#Import mode images in list\n",
    "\n",
    "folderModePath = 'Resources/modes'\n",
    "modePath= os.listdir(folderModePath)\n",
    "imgModeList=[]\n",
    "for path in modePath:\n",
    "    imgModeList.append(cv2.imread(os.path.join(folderModePath, path)))\n",
    "\n",
    "#print(len(imgModeList))\n",
    "\n",
    "#Load the encoding file\n",
    "print(\"Loading Encode File...\")\n",
    "\n",
    "file = open('EncodeFile.p','rb')\n",
    "encodeListKnownWithIds = pickle.load(file)\n",
    "file.close()\n",
    "encodeListKnown,studentIds = encodeListKnownWithIds\n",
    "print(studentIds)\n",
    "print(\"Encode File Loaded\")\n",
    "\n",
    "modeType = 0\n",
    "counter = 0\n",
    "id = 0\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "\n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    faceCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodeCurFrame = face_recognition.face_encodings(imgS, faceCurFrame)\n",
    "    \n",
    "    imgBackground[162:162+480,55:55+640] = img\n",
    "    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "    \n",
    "    for encodeFace,faceLoc in zip(encodeCurFrame, faceCurFrame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown,encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown,encodeFace)\n",
    "        \n",
    "        #print(\"matches\", matches)\n",
    "        #print(\"faceDis\", faceDis)\n",
    "        \n",
    "        matchIndex = np.argmin(faceDis)\n",
    "\n",
    "        if matches[matchIndex]:\n",
    "            #print(\"known\")\n",
    "            #print(studentIds[matchIndex])\n",
    "            y1, x2, y2, x1 = faceLoc\n",
    "            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "            bbox = 55 + x1, 162 + y1, x2 - x1, y2 - y1\n",
    "            imgBackground = cvzone.cornerRect(imgBackground,bbox,rt=0)\n",
    "            \n",
    "            id = studentIds[matchIndex]\n",
    "            \n",
    "            if counter == 0:\n",
    "                counter = 1\n",
    "                modType = 1\n",
    "    if counter != 0:\n",
    "\n",
    "        if counter == 1:\n",
    "            studentInfo = db.reference(f'Students/{id}').get()\n",
    "            print(studentInfo)\n",
    "\n",
    "        cv2.putText(imgBackground,str(studentInfo['total_attendance']),(861,125),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),1)\n",
    "        \n",
    "        \n",
    "        counter += 1\n",
    "    \n",
    "    # cv2.imshow(\"Webcam\", img)\n",
    "    cv2.imshow(\"Face Attendance\", imgBackground)\n",
    "\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):  # Exit loop if 'q' is pressed\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0931908-60bf-45be-a46d-b52e10b872cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Encode File...\n",
      "['321654', '852741', '963852']\n",
      "Encode File Loaded\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "inside\n",
      "{'last_attendance_time': '2024-03-25 00:54:34', 'major': 'CSE', 'name': 'Akash S', 'standing': 'G', 'starting_year': 2020, 'total_attendance': 10, 'year': 4}\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "imgBackground = cv2.imread('Resources/background.png')\n",
    "\n",
    "#Import mode images in list\n",
    "\n",
    "folderModePath = 'Resources/modes'\n",
    "modePath= os.listdir(folderModePath)\n",
    "imgModeList=[]\n",
    "for path in modePath:\n",
    "    imgModeList.append(cv2.imread(os.path.join(folderModePath, path)))\n",
    "\n",
    "#print(len(imgModeList))\n",
    "\n",
    "#Load the encoding file\n",
    "print(\"Loading Encode File...\")\n",
    "\n",
    "file = open('EncodeFile.p','rb')\n",
    "encodeListKnownWithIds = pickle.load(file)\n",
    "file.close()\n",
    "encodeListKnown,studentIds = encodeListKnownWithIds\n",
    "print(studentIds)\n",
    "print(\"Encode File Loaded\")\n",
    "\n",
    "modeType = 0\n",
    "counter = 0\n",
    "id = 0\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "\n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    faceCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodeCurFrame = face_recognition.face_encodings(imgS, faceCurFrame)\n",
    "    \n",
    "    imgBackground[162:162+480,55:55+640] = img\n",
    "    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "    \n",
    "    for encodeFace,faceLoc in zip(encodeCurFrame, faceCurFrame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown,encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown,encodeFace)\n",
    "        \n",
    "        #print(\"matches\", matches)\n",
    "        #print(\"faceDis\", faceDis)\n",
    "        \n",
    "        matchIndex = np.argmin(faceDis)\n",
    "\n",
    "        if matches[matchIndex]:\n",
    "            #print(\"known\")\n",
    "            #print(studentIds[matchIndex])\n",
    "            y1, x2, y2, x1 = faceLoc\n",
    "            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "            bbox = 55 + x1, 162 + y1, x2 - x1, y2 - y1\n",
    "            imgBackground = cvzone.cornerRect(imgBackground,bbox,rt=0)\n",
    "            \n",
    "            id = studentIds[matchIndex]\n",
    "            if counter == 0:\n",
    "                counter = 1\n",
    "                modeType = 1\n",
    "                \n",
    "    if counter != 0:\n",
    "\n",
    "        if counter == 1:\n",
    "            studentInfo = db.reference(f'Students/{id}').get()\n",
    "            #print(studentInfo\n",
    "\n",
    "        cv2.putText(imgBackground,str(studentInfo['total_attendance']),(861,125),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),1)\n",
    "        cv2.putText(imgBackground,str(studentInfo['']),(861,125),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),1)\n",
    "        cv2.putText(imgBackground,str(studentInfo['total_attendance']),(861,125),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),1)\n",
    "        \n",
    "        \n",
    "        counter += 1\n",
    "    \n",
    "    # cv2.imshow(\"Webcam\", img)\n",
    "    cv2.imshow(\"Face Attendance\", imgBackground)\n",
    "\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):  # Exit loop if 'q' is pressed\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#before changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b89462b3-a974-4d78-9937-dcfd58eb5701",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bucket' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m bucket \u001b[38;5;241m=\u001b[39m bucket\u001b[38;5;241m.\u001b[39mstorage() \n\u001b[0;32m      4\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      5\u001b[0m cap\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m640\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bucket' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bucket = bucket.storage() \n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "imgBackground = cv2.imread('Resources/background.png')\n",
    "\n",
    "#Import mode images in list\n",
    "\n",
    "folderModePath = 'Resources/modes'\n",
    "modePath= os.listdir(folderModePath)\n",
    "imgModeList=[]\n",
    "for path in modePath:\n",
    "    imgModeList.append(cv2.imread(os.path.join(folderModePath, path)))\n",
    "\n",
    "#print(len(imgModeList))\n",
    "\n",
    "#Load the encoding file\n",
    "print(\"Loading Encode File...\")\n",
    "\n",
    "file = open('EncodeFile.p','rb')\n",
    "encodeListKnownWithIds = pickle.load(file)\n",
    "file.close()\n",
    "encodeListKnown,studentIds = encodeListKnownWithIds\n",
    "print(studentIds)\n",
    "print(\"Encode File Loaded\")\n",
    "\n",
    "modeType = 0\n",
    "counter = 0\n",
    "id = 0\n",
    "imgStudent = []\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "\n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    faceCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodeCurFrame = face_recognition.face_encodings(imgS, faceCurFrame)\n",
    "    \n",
    "    imgBackground[162:162+480,55:55+640] = img\n",
    "    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "    \n",
    "    for encodeFace,faceLoc in zip(encodeCurFrame, faceCurFrame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown,encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown,encodeFace)\n",
    "        \n",
    "        #print(\"matches\", matches)\n",
    "        #print(\"faceDis\", faceDis)\n",
    "        \n",
    "        matchIndex = np.argmin(faceDis)\n",
    "\n",
    "        if matches[matchIndex]:\n",
    "            #print(\"known\")\n",
    "            #print(studentIds[matchIndex])\n",
    "            y1, x2, y2, x1 = faceLoc\n",
    "            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "            bbox = 55 + x1, 162 + y1, x2 - x1, y2 - y1\n",
    "            imgBackground = cvzone.cornerRect(imgBackground,bbox,rt=0)\n",
    "            \n",
    "            id = studentIds[matchIndex]\n",
    "            if counter == 0:\n",
    "                counter = 1\n",
    "                modeType = 1\n",
    "                \n",
    "    if counter != 0:\n",
    "\n",
    "        if counter == 1:\n",
    "            studentInfo = db.reference(f'Students/{id}').get()\n",
    "            #print(studentInfo)\n",
    "            # get the image for db\n",
    "            blob.bucket.get_blob(f'Images/{id}.png')\n",
    "            array = np.frombuffer(blob.download_as_string().np.uint8)\n",
    "            imgStudent = cv2.imdecode(array, cv2.COLOR_BGRA2BGR)\n",
    "        \n",
    "\n",
    "        cv2.putText(imgBackground, str(studentInfo['total_attendance']), (861, 125),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 1)\n",
    "        cv2.putText(imgBackground, str(studentInfo['major']), (1006, 550),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        cv2.putText(imgBackground, str(id), (1006, 493),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        cv2.putText(imgBackground, str(studentInfo['standing']), (910, 625),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.6, (100, 100, 100), 1)\n",
    "        cv2.putText(imgBackground, str(studentInfo['year']), (1025, 625),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.6, (100, 100, 100), 1)\n",
    "        cv2.putText(imgBackground, str(studentInfo['starting_year']), (1125, 625),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.6, (100, 100, 100), 1)\n",
    "\n",
    "        (w, h), _ = cv2.getTextSize(studentInfo['name'], cv2.FONT_HERSHEY_COMPLEX, 1, 1)\n",
    "        offset = (414 - w) // 2\n",
    "        cv2.putText(imgBackground, str(studentInfo['name']), (808 + offset, 445),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 1, (50, 50, 50), 1)\n",
    "        \n",
    "        imgBackground[175:175 + 216, 909:909 + 216] = imgStudent\n",
    "        \n",
    "        counter += 1\n",
    "    \n",
    "    # cv2.imshow(\"Webcam\", img)\n",
    "    cv2.imshow(\"Face Attendance\", imgBackground)\n",
    "\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):  # Exit loop if 'q' is pressed\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bad47f13-86c7-4617-91e6-bd102f6bcbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<firebase_admin.App at 0x23d82af8a50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import cvzone \n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import db\n",
    "from firebase_admin import storage\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "cred = credentials.Certificate(\"serviceAccountKey.json\")\n",
    "firebase_admin.initialize_app(cred,{\n",
    "    'databaseURL':\"https://faceattendancerealtime-a1b14-default-rtdb.firebaseio.com/\",\n",
    "    'storageBucket':\"faceattendancerealtime-a1b14.appspot.com\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ec5776-d0c1-4372-917e-d58aa6b380be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Encode File...\n",
      "['321654', '852741', '963852']\n",
      "Encode File Loaded\n",
      "65413.491488\n",
      "27.792021\n",
      "29.683999\n",
      "31.361607\n",
      "15.428989\n",
      "37.139996\n",
      "65659.647709\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bucket = storage.bucket() \n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "imgBackground = cv2.imread('Resources/background.png')\n",
    "\n",
    "#Import mode images in list\n",
    "\n",
    "folderModePath = 'Resources/modes'\n",
    "modePath= os.listdir(folderModePath)\n",
    "imgModeList=[]\n",
    "for path in modePath:\n",
    "    imgModeList.append(cv2.imread(os.path.join(folderModePath, path)))\n",
    "\n",
    "#print(len(imgModeList))\n",
    "\n",
    "#Load the encoding file\n",
    "print(\"Loading Encode File...\")\n",
    "\n",
    "file = open('EncodeFile.p','rb')\n",
    "encodeListKnownWithIds = pickle.load(file)\n",
    "file.close()\n",
    "encodeListKnown,studentIds = encodeListKnownWithIds\n",
    "print(studentIds)\n",
    "print(\"Encode File Loaded\")\n",
    "\n",
    "modeType = 0\n",
    "counter = 0\n",
    "id = 0\n",
    "imgStudent = []\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "\n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    faceCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodeCurFrame = face_recognition.face_encodings(imgS, faceCurFrame)\n",
    "    \n",
    "    imgBackground[162:162+480,55:55+640] = img\n",
    "    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "\n",
    "    if faceCurFrame: \n",
    "        for encodeFace,faceLoc in zip(encodeCurFrame, faceCurFrame):\n",
    "            matches = face_recognition.compare_faces(encodeListKnown,encodeFace)\n",
    "            faceDis = face_recognition.face_distance(encodeListKnown,encodeFace)\n",
    "            \n",
    "            #print(\"matches\", matches)\n",
    "            #print(\"faceDis\", faceDis)\n",
    "            \n",
    "            matchIndex = np.argmin(faceDis)\n",
    "    \n",
    "            if matches[matchIndex]:\n",
    "                #print(\"known\")\n",
    "                #print(studentIds[matchIndex])\n",
    "                y1, x2, y2, x1 = faceLoc\n",
    "                y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "                bbox = 55 + x1, 162 + y1, x2 - x1, y2 - y1\n",
    "                imgBackground = cvzone.cornerRect(imgBackground,bbox,rt=0)\n",
    "                \n",
    "                id = studentIds[matchIndex]\n",
    "                if counter == 0:\n",
    "                    cvzone.putTextRect(imgBackground,\"Loading\",(275,400))\n",
    "                    cv2.imshow(\"Face Attendance\", imgBackground)\n",
    "                    cv2.waitKey(1)\n",
    "                    counter = 1\n",
    "                    modeType = 1\n",
    "                    \n",
    "        if counter != 0:\n",
    "    \n",
    "            if counter == 1:\n",
    "                studentInfo = db.reference(f'Students/{id}').get()\n",
    "                #print(studentInfo)\n",
    "                \n",
    "                # get the image for db\n",
    "                blob=bucket.get_blob(f'Images/{id}.png')\n",
    "                array = np.frombuffer(blob.download_as_string(),np.uint8)\n",
    "                imgStudent = cv2.imdecode(array, cv2.COLOR_BGRA2BGR)\n",
    "    \n",
    "                #update data attendance\n",
    "                datetimeObject = datetime.strptime(studentInfo['last_attendance_time'],\n",
    "                                                       \"%Y-%m-%d %H:%M:%S\")\n",
    "                secondsElapsed = (datetime.now() - datetimeObject).total_seconds()\n",
    "                print(secondsElapsed)\n",
    "                if secondsElapsed > 30:\n",
    "                    ref = db.reference(f'Students/{id}')\n",
    "                    studentInfo['total_attendance'] +=1\n",
    "                    ref.child('total_attendance').set(studentInfo['total_attendance'])\n",
    "                    ref.child('last_attendance_time').set(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "                else:\n",
    "                    modeType = 3\n",
    "                    counter = 0\n",
    "                    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "            if modeType != 3 :\n",
    "                        \n",
    "                if 10< counter < 20:\n",
    "                    modeType = 2\n",
    "        \n",
    "                imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "                \n",
    "                if counter<=10:\n",
    "                    cv2.putText(imgBackground, str(studentInfo['total_attendance']), (861, 125),\n",
    "                                            cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 1)\n",
    "                    cv2.putText(imgBackground, str(studentInfo['major']), (1006, 550),\n",
    "                                            cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                    cv2.putText(imgBackground, str(id), (1006, 493),\n",
    "                                            cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                    cv2.putText(imgBackground, str(studentInfo['standing']), (910, 625),\n",
    "                                            cv2.FONT_HERSHEY_COMPLEX, 0.6, (100, 100, 100), 1)\n",
    "                    cv2.putText(imgBackground, str(studentInfo['year']), (1025, 625),\n",
    "                                            cv2.FONT_HERSHEY_COMPLEX, 0.6, (100, 100, 100), 1)\n",
    "                    cv2.putText(imgBackground, str(studentInfo['starting_year']), (1125, 625),\n",
    "                                            cv2.FONT_HERSHEY_COMPLEX, 0.6, (100, 100, 100), 1)\n",
    "            \n",
    "                    (w, h), _ = cv2.getTextSize(studentInfo['name'], cv2.FONT_HERSHEY_COMPLEX, 1, 1)\n",
    "                    offset = (414 - w) // 2\n",
    "                    cv2.putText(imgBackground, str(studentInfo['name']), (808 + offset, 445),\n",
    "                                            cv2.FONT_HERSHEY_COMPLEX, 1, (50, 50, 50), 1)\n",
    "                    \n",
    "                    imgBackground[175:175 + 216, 909:909 + 216] = imgStudent\n",
    "            \n",
    "            counter += 1\n",
    "    \n",
    "            if counter>=20:\n",
    "                counter = 0\n",
    "                modeType = 0\n",
    "                studentInfo = []\n",
    "                imgStudent = []\n",
    "                imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "    else:\n",
    "        modeType = 0\n",
    "        counter = 0\n",
    "    \n",
    "    # cv2.imshow(\"Webcam\", img)\n",
    "    cv2.imshow(\"Face Attendance\", imgBackground)\n",
    "\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):  # Exit loop if 'q' is pressed\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152600ba-acc3-4805-9c02-7af054cb2c20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
